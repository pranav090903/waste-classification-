# -*- coding: utf-8 -*-
"""Garbage_Classification_Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cZwrokJ0lvMMQpOt11PFPj-cQ9JFg9I1
"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d sumn2u/garbage-classification-v2

!unzip -q garbage-classification-v2.zip -d /content/dataset/

!ls /content/dataset

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
import matplotlib.pyplot as plt

print("TensorFlow version:", tf.__version__)

train_path = '/content/dataset/garbage-dataset/train'
test_path  = '/content/dataset/garbage-dataset/test'

train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_gen = train_datagen.flow_from_directory(
    train_path,
    target_size=(128,128),
    batch_size=32,
    subset='training'
)

val_gen = train_datagen.flow_from_directory(
    train_path,
    target_size=(128,128),
    batch_size=32,
    subset='validation'
)

!ls /content/dataset
!ls /content/dataset/garbage-dataset

train_path = '/content/dataset/garbage-dataset'

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

train_gen = train_datagen.flow_from_directory(
    train_path,
    target_size=(128,128),
    batch_size=32,
    subset='training'
)

val_gen = train_datagen.flow_from_directory(
    train_path,
    target_size=(128,128),
    batch_size=32,
    subset='validation'
)

# Step 12 - Build the CNN Model

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.3),

    Dense(train_gen.num_classes, activation='softmax')  # matches your dataset’s 10 classes
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Display model summary
model.summary()

# Step 13 - Train the CNN Model

history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=10
)

# Step 14 - Save the trained model
model.save('waste_classifier_model.h5')
print("✅ Model saved successfully!")

import matplotlib.pyplot as plt

# Accuracy Graph
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Loss Graph
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

import numpy as np
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt

# Pick any one image from your dataset folder to test
img_path = '/content/dataset/garbage-dataset/plastic/plastic1.jpg'   # you can change this file name

# Load and preprocess the image
img = image.load_img(img_path, target_size=(128,128))
img_array = image.img_to_array(img)/255.0
img_array = np.expand_dims(img_array, axis=0)

# Make prediction
prediction = model.predict(img_array)
predicted_class = list(train_gen.class_indices.keys())[np.argmax(prediction)]

# Show the image and result
plt.imshow(image.load_img(img_path))
plt.axis('off')
plt.title(f'Predicted: {predicted_class}', fontsize=14)
plt.show()

print("✅ Predicted class:", predicted_class)
print("Image array shape:", img_array.shape)

!ls /content/dataset/garbage-dataset/plastic

img_path = '/content/dataset/garbage-dataset/plastic/plastic_958.jpg'

import numpy as np
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt

img_path = '/content/dataset/garbage-dataset/plastic/plastic_958.jpg'   # your correct file

img = image.load_img(img_path, target_size=(128,128))
img_array = image.img_to_array(img)/255.0
img_array = np.expand_dims(img_array, axis=0)

prediction = model.predict(img_array)
predicted_class = list(train_gen.class_indices.keys())[np.argmax(prediction)]

plt.imshow(image.load_img(img_path))
plt.axis('off')
plt.title(f'Predicted: {predicted_class}', fontsize=14)
plt.show()

print("✅ Predicted class:", predicted_class)
print("Image array shape:", img_array.shape)

from google.colab import files
files.download('waste_classifier_model.h5')

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

# Recreate the same model structure
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.3),

    Dense(10, activation='softmax')  # 10 classes in your dataset
])

# Compile it again
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

